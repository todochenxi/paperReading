# cot
- cot prompt 是模型规模的产物，也就是说，cot prompt对小模型没有正面影响，仅当与大约100亿参数的模型一起使用时才能产生性能改进，并且
更小规模的模型铲形流浪但不和逻辑的思维链，导致其性能低于标准提示。
- cot对更复杂的问题有更大的性能挨近
- 数据集：五个数学文字题基准测试集，还有5个常识推理类型的数据集

# autocot

- cot 有两种范式
 - zero-shot-cot
 - few-shot-prompting
 - auto-cot，利用带有“让我们一步一步思考”提示的语言模型为演示逐个生成推理
 - 流程
 - 
    问题聚类
    利用Sentence-BERT对所有问题进行向量化表示,得到固定长度的向量
    对所有的问题向量进行K-means聚类,将问题划分为k个簇
    每个簇内部根据距离中心点的远近对问题进行排序
这样可以capture不同类型问题的语义信息,聚出一些generic的问题模式。
 - 
    演示采样
    对每个簇选取排序靠前的问题,利用Zero-Shot CoT生成该问题的完整推理链(包括步骤和答案)
    根据问题和推理链长度的简单启发式,选择满足要求的作为该簇的代表性演示
    最终获得k个簇,每个簇采样一个满足要求的演示
这样可以自动获取一些高质量的推理演示,覆盖不同类型的问题。
 - 
    增强测试问题
    将k个演示连接起来,放在测试问题prompt前面
    输入到GPT-3中,生成测试问题的完整推理链
这样通过不同类型演示的上下文调节,可以增强测试问题的推理能力。
 - 
    流式设置
    初始阶段用零试验;之后利用已有的问题链对进行采样
这样可以适应更动态的环境。
总体来说,Auto-CoT的技术核心是引入问题聚类和采样,实现了自动高质量演示的生成,从而达到增强推理的效果。